<h1 align="center">
  <img src="docs/images/akgunicon.png" width="80">  
  <br>
  LLaMa 3.1 Chatbox Servisi - AKGÃœN YAZILIM
</h1>

---

Bu proje, [LLaMa 3.1](https://ollama.com/library/llama3.1:8b) modelinin en dÃ¼ÅŸÃ¼k kaynak gereksinimine sahip sÃ¼rÃ¼mÃ¼nÃ¼ kullanarak basit bir sohbet (chat) servisi sunmayÄ± amaÃ§lar. Flask tabanlÄ± bir REST API Ã¼zerinden Postman gibi araÃ§larla mesaj gÃ¶nderip model yanÄ±tÄ± alabilirsiniz.

## Ã–zellikler

- **LLaMa 3.1 Modeli:** Ollama CLI aracÄ±lÄ±ÄŸÄ±yla lokal makinede Ã§alÄ±ÅŸÄ±r.
- **Flask REST API:** Basit bir `/chat` endpointâ€™i Ã¼zerinden mesaj alÄ±p yanÄ±t dÃ¶ndÃ¼rÃ¼r.
- **JSON FormatÄ±:** Hem istek hem de yanÄ±tlar JSON formatÄ±ndadÄ±r.
- **Kolay Entegrasyon:** Postman, cURL veya herhangi bir HTTP istemcisiyle test edilebilir.

---

## Gereksinimler

1. **Python 3.7+** (Python 3.9 veya Ã¼stÃ¼ Ã¶nerilir)
2. **Flask** kÃ¼tÃ¼phanesi
3. **Ollama CLI** (LLaMa 3.1 modelini Ã§alÄ±ÅŸtÄ±rmak iÃ§in)
4. **LLaMa 3.1 (8B)** model dosyasÄ± (lokalde indirili olmalÄ±)

> LLaMa 3.1 modeli, Ollama platformu Ã¼zerinden indirilebilir ve lokal makinede Ã§alÄ±ÅŸtÄ±rÄ±labilir. AÅŸaÄŸÄ±daki adÄ±mlarÄ± takip ederek Ollama ve LLaMa 3.1 modelini yÃ¼kleyip test edebilirsiniz.
> Ollama ve LLaMa 3.1 model kurulum adÄ±mlarÄ± iÃ§in [ollama resmi dokÃ¼mantasyonuna](https://ollama.com/library/llama3.1) gÃ¶z atabilirsiniz.

---

# ğŸš€ Kurulum & Ã‡alÄ±ÅŸtÄ±rma

## 1ï¸âƒ£ Ollama ve LLaMa 3.1 Modelini Kurun
LLaMa 3.1 modelini kullanabilmek iÃ§in Ã¶nce **Ollama CLI** aracÄ±nÄ± yÃ¼klemeniz gerekmektedir.

ğŸ“Œ macOS (Homebrew ile)
```bash
brew install ollama
```
ğŸ“Œ Linux (Debian / Ubuntu)
```bash
curl -fsSL https://ollama.com/install.sh | sh
```
ğŸ“Œ Windows (Manuel Kurulum)
Windows kullanÄ±cÄ±larÄ± Ollamaâ€™yÄ± aÅŸaÄŸÄ±daki adÄ±mlarla yÃ¼kleyebilir:

1. **Ollamaâ€™nÄ±n resmi yÃ¼kleyicisini indirin:**  
   ğŸ”— [Ollama Windows YÃ¼kleyicisi](https://ollama.com/download/windows)

2. **Ä°ndirilen `.exe` dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n ve yÃ¼kleme adÄ±mlarÄ±nÄ± tamamlayÄ±n.**


Kurulum tamamlandÄ±ktan sonra terminali kapatÄ±p yeniden aÃ§Ä±n ve aÅŸaÄŸÄ±daki komut ile Ollama'nÄ±n baÅŸarÄ±yla yÃ¼klendiÄŸini doÄŸrulayÄ±n:
```bash
ollama --version
```
EÄŸer ÅŸu ÅŸekilde bir Ã§Ä±ktÄ± alÄ±yorsanÄ±z, Ollama baÅŸarÄ±yla kurulmuÅŸtur:
```bash
ollama 0.1.20
```

## 2ï¸âƒ£ LLaMa 3.1 Modelini Ä°ndirin
Ollama baÅŸarÄ±yla kurulduktan sonra, LLaMa 3.1 (8B) modelini bilgisayarÄ±nÄ±za indirmek iÃ§in ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
```bash
ollama pull llama3.1:8b
```
Model baÅŸarÄ±yla indirildiÄŸinde, aÅŸaÄŸÄ±daki komut ile yÃ¼klÃ¼ modelleri listeleyebilirsiniz:
```bash
ollama list
```
Ã‡Ä±ktÄ± ÅŸu ÅŸekilde olmalÄ±dÄ±r:
| NAME      | ID             | SIZE  | MODIFIED    |
|-----------|---------------|-------|------------|
| llama3.1:8b | 46e0c10c039e | 4.9 GB | .. minutes ago |

Bu, modelin baÅŸarÄ±yla indirildiÄŸini ve kullanÄ±lmaya hazÄ±r olduÄŸunu gÃ¶sterir.


## 3ï¸âƒ£ Projeyi KlonlayÄ±n ve Ã‡alÄ±ÅŸtÄ±rÄ±n
1. **Projeyi KlonlayÄ±n**
```bash
git clone https://github.com/aliakkayamain/Akgun-Chatbox.git
```
**Åimdi projenin iÃ§ine girin:**
```bash
cd Akgun-Chatbot
```

2. **Sanal Ortam OluÅŸturun ve Aktif Edin**
```bash
python -m venv venv
```
ğŸ“Œ Windows iÃ§in
```bash
venv\Scripts\activate
```
ğŸ“Œ macOS/Linux iÃ§in
```bash
source venv/bin/activate
```

3. **Gerekli KÃ¼tÃ¼phaneleri YÃ¼kleyin**
```bash
pip install -r requirements.txt
```

4. **API'yi BaÅŸlatÄ±n**
```bash
python app.py
```
VarsayÄ±lan olarak sunucu http://127.0.0.1:5000 adresinde Ã§alÄ±ÅŸacaktÄ±r.

---

# ğŸ’¬ API KullanÄ±mÄ±

### ğŸ“Œ Sohbet APIâ€™si (POST /chat)

Postman ile Test
Postman kullanarak http://127.0.0.1:5000/chat adresine aÅŸaÄŸÄ±daki JSON formatÄ±nda istek atabilirsiniz:

ğŸ”¹ **Ä°stek (JSON GÃ¶nderimi)**  
```json
{
    "message": "Merhaba, nasÄ±lsÄ±n?"
}
```

ğŸ”¹ **YanÄ±t (JSON DÃ¶ndÃ¼rÃ¼len Cevap)**
```json
{
    "response": "Merhaba! Ben iyiyim, size nasÄ±l yardÄ±mcÄ± olabilirim?"
}
```

---

# ğŸ“· API Test GÃ¶rÃ¼ntÃ¼sÃ¼
![Postman Testi](docs/images/screen_shot2.png)

---

# ğŸ“‚ Proje YapÄ±sÄ±
```
AKGUN-CHATBOX/
â”‚
â”œâ”€â”€ __pycache__/         # Python tarafÄ±ndan derlenen bytecode dosyalarÄ±
â”‚
â”œâ”€â”€ docs/                # DÃ¶kÃ¼manlar ve ekran gÃ¶rÃ¼ntÃ¼leri iÃ§in ayrÄ±lmÄ±ÅŸ klasÃ¶r
â”‚   â””â”€â”€ images/          # Proje ile ilgili ekran gÃ¶rÃ¼ntÃ¼leri
â”‚
â”œâ”€â”€ routes/              # API endpoint'lerini iÃ§eren klasÃ¶r
â”‚   â”œâ”€â”€ __pycache__/     # Python tarafÄ±ndan derlenen bytecode dosyalarÄ±
â”‚   â”œâ”€â”€ chat.py          # "/chat" endpoint'ini tanÄ±mlayan kodlar
â”‚   â””â”€â”€ index.py         # "/" (root) endpoint'ini tanÄ±mlayan kodlar
â”‚
â”œâ”€â”€ .gitignore           # Git'e dahil edilmemesi gereken dosyalarÄ± belirleyen ayarlar
â”œâ”€â”€ app.py               # Flask uygulamasÄ±nÄ±n ana giriÅŸ noktasÄ± ve blueprint kayÄ±tlarÄ±
â”œâ”€â”€ config.py            # KonfigÃ¼rasyon ayarlarÄ± (Ã¶rn. DEBUG, PORT vb.)
â”œâ”€â”€ README.md            # Proje dokÃ¼mantasyonu
â”œâ”€â”€ requirements.txt     # Proje baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ±n listesi (Flask vb.)
â””â”€â”€ venv/                # Python sanal ortam (virtual environment) klasÃ¶rÃ¼
```

---

# ğŸ“Œ HakkÄ±nda

Bu proje **Ali Akkaya** tarafÄ±ndan **AkgÃ¼n YazÄ±lÄ±m** iÃ§in geliÅŸtirilmiÅŸtir.  
LLaMa 3.1 modeli kullanÄ±larak oluÅŸturulan bu sohbet botu, Flask tabanlÄ± bir REST API ile entegre edilmiÅŸtir ve yerel olarak Ã§alÄ±ÅŸtÄ±rÄ±labilir.

ğŸ’¡ **Proje AmacÄ±:**  
Bu proje, yapay zeka modelleriyle temel dÃ¼zeyde Ã§alÄ±ÅŸma ve API entegrasyonu becerilerini geliÅŸtirmek amacÄ±yla hazÄ±rlanmÄ±ÅŸtÄ±r.

---

## ğŸ“¬ Ä°letiÅŸim  

ğŸ“© **GeliÅŸtirici:** Ali Akkaya  
ğŸ“§ **E-posta:** [aliakkayamain@gmail.com](mailto:aliakkayamain@gmail.com)  
